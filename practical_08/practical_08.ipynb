{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical: Image classification\n",
    "\n",
    "In this practical, we will continue working on the hand-written digit classification dataset, [MNIST](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "![](mnist.png)\n",
    "\n",
    "Instead of using a K nearest neighbour or support vector machine classifier from sklearn in the previous practical, we will use a convolutional neural network today.\n",
    "\n",
    "The two mainstream neural network libraries are [TensorFlow](https://www.tensorflow.org/) by Google and [PyTorch](https://pytorch.org/) by Facebook. We will use PyTorch for this practical. Please install the package first, following the [instruction](https://pytorch.org/get-started/locally/). In most cases, you simply need to run the following command on your computer:\n",
    "\n",
    "`pip3 install torch torchvision`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libaries (provided)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# If you use Macbook and get an error message when you use matplotlib, relevant to libomp.dylib initialisation, you may try uncommenting the following line.\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output of the `extract_images()` function is a 4D array. The [convolutational layer](https://pytorch.org/docs/stable/nn.html#conv2d) in Pytorch takes 4D arrays of shape $N \\times C \\times X \\times Y$ as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for loading MNIST image data (provided)\n",
    "def extract_images(f_name):\n",
    "    \"\"\" Extract the images into a 4D uint8 numpy array [index, rows, cols, 1]. \"\"\"\n",
    "    print('Extracting', f_name)\n",
    "    with gzip.open(f_name, 'rb') as f:\n",
    "        # Read file header\n",
    "        buffer = f.read(16)\n",
    "        magic, num_images, rows, cols = struct.unpack(\">IIII\", buffer)\n",
    "        if magic != 2051:\n",
    "            raise ValueError('Invalid magic number {0} in MNIST image file {1}.'.format(magic, f_name))\n",
    "\n",
    "        # Read data\n",
    "        buffer = f.read(rows * cols * num_images)\n",
    "        data = np.frombuffer(buffer, dtype=np.uint8)\n",
    "        data = data.reshape(num_images, 1, rows, cols)\n",
    "        return data\n",
    "\n",
    "# Functions for loading MNIST label data (provided)\n",
    "def extract_labels(f_name):\n",
    "    \"\"\" Extract the labels into a 1D uint8 numpy vector [index,]. \"\"\"\n",
    "    print('Extracting', f_name)\n",
    "    with gzip.open(f_name, 'rb') as f:\n",
    "        # Read file header\n",
    "        buffer = f.read(8)\n",
    "        magic, num_items = struct.unpack(\">II\", buffer)\n",
    "        if magic != 2049:\n",
    "            raise ValueError('Invalid magic number {0} in MNIST label file {1}.'.format(magic, f_name))\n",
    "\n",
    "        # Read data\n",
    "        buffer = f.read(num_items)\n",
    "        data = np.frombuffer(buffer, dtype=np.uint8)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and browse data.\n",
    "\n",
    "The MNIST dataset is split into a training set (60,000 samples) and a test set (10,000 samples). In total, there are 4 files.\n",
    "\n",
    "* `train-images-idx3-ubyte.gz`: training images\n",
    "* `train-labels-idx1-ubyte.gz`: training labels\n",
    "* `t10k-images-idx3-ubyte.gz`: test images\n",
    "* `t10k-labels-idx1-ubyte.gz`: test labels\n",
    "\n",
    "#### 1.1 Load data (provided)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "X_train = extract_images('../practical_07/train-images-idx3-ubyte.gz')\n",
    "y_train = extract_labels('../practical_07/train-labels-idx1-ubyte.gz')\n",
    "\n",
    "# Test set\n",
    "X_test = extract_images('../practical_07/t10k-images-idx3-ubyte.gz')\n",
    "y_test = extract_labels('../practical_07/t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Print out the shapes of the four arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse data.\n",
    "\n",
    "We are going to provide you with the framework of a convolutional neural network. However, some bits and pieces are missing, which need to be completed by you.\n",
    "\n",
    "The network provided has an architecture like this, only with minor differences. For example, our input is of shape 28 x 28, instead of 32 x 32.\n",
    "\n",
    "![](lenet.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Build the network (provided).\n",
    "\n",
    "You can read the code here and compare to the LeNet architecture shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LeNet (provided)\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # Construct the layers. The layer names are corresponding to the annotations in the figure above.\n",
    "        self.C1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(5, 5), padding=2)\n",
    "        self.S2 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.C3 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5, 5))\n",
    "        self.S4 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.C5 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=(5, 5))\n",
    "        self.F6 = nn.Linear(120, 84)\n",
    "        self.F7 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward propagation\n",
    "        x = F.relu(self.C1(x))\n",
    "        x = self.S2(x)\n",
    "        x = F.relu(self.C3(x))\n",
    "        x = self.S4(x)\n",
    "        x = F.relu(self.C5(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.F6(x))\n",
    "        x = F.relu(self.F7(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Train the neural network.\n",
    "\n",
    "During each iteration of training, load a random batch of images and labels, feed them to the network to perform stochastic gradient descent.\n",
    "\n",
    "Please fill in the missing code to make this working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Since most of you use laptops, we use CPU for training.\n",
    "device = 'cpu'\n",
    "# If some of you would like to try GPU. You can set the device to be CUDA.\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Network\n",
    "model = LeNet().to(device)\n",
    "\n",
    "# Define the cross entropy loss function\n",
    "# Fill in code\n",
    "criterion = ...\n",
    "\n",
    "# Optimiser and learning rate\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "\n",
    "# Number of iterations for training\n",
    "num_iter = 1000\n",
    "loss_curve = []\n",
    "\n",
    "# Train model\n",
    "start = time.time()\n",
    "for it in range(num_iter):\n",
    "    # Set the modules in training mode, which will have effects on certain modules, e.g. dropout or batchnorm.\n",
    "    start_iter = time.time()\n",
    "    model.train()\n",
    "\n",
    "    # Get a random batch of images and labels from X_train and y_train\n",
    "    train_batch_size = 32\n",
    "    # image: batch_size x 1 x X x Y array\n",
    "    # label: batch_size vector\n",
    "    # Fill in code\n",
    "    image, label = ...\n",
    "    \n",
    "    # Convert the batch of images and labels into PyTorch tensors on the device    \n",
    "    image, label = torch.from_numpy(image).float(), torch.from_numpy(label).long()\n",
    "    image, label = image.to(device), label.to(device)\n",
    "    output = model(image)\n",
    "\n",
    "    # The loss for the current batch\n",
    "    # Fill in code\n",
    "    loss = ...\n",
    "        \n",
    "    # Perform stochastic gradient descent\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print information\n",
    "    loss_curve += [loss.item()]\n",
    "    print('--- Iteration {0}: training loss = {1:.4f}, {2:.4f} s ---'.format(it + 1, loss.item(), time.time() - start_iter))\n",
    "print('Training took {:.3f}s in total.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Plot the training loss curve, which is stored in the variable loss_curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Apply the model onto the full test set (provided)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy model\n",
    "start = time.time()\n",
    "model.eval()\n",
    "image = X_test\n",
    "image = torch.from_numpy(image).float()\n",
    "image = image.to(device)\n",
    "output = model(image)\n",
    "y_pred = output.argmax(dim=1, keepdim=True).numpy().flatten()\n",
    "print('Testing took {:.3f}s in total.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Evaluate the classification accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Is the accuracy satisfactory? What would you do to improve the accuracy?\n",
    "\n",
    "#### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
